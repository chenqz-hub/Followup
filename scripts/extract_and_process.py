"""
ä¸€é”®å¼éšè®¿æ•°æ®å¤„ç†æµç¨‹

ä»åŸå§‹å¤§æ–‡ä»¶ä¸­è‡ªåŠ¨æå–éšè®¿è¡¨Sheetå¹¶å¤„ç†ã€‚
æ”¯æŒä»åŒ…å«å¤šä¸ªSheetçš„åŸå§‹æ–‡ä»¶ä¸­æå–"*éšè®¿è¡¨1"çš„Sheetï¼Œ
é‡ç»„ä¸ºæ ‡å‡†æ ¼å¼åè¿›è¡Œçºµå‘éšè®¿æ•°æ®å¤„ç†ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/extract_and_process.py [åŸå§‹æ–‡ä»¶è·¯å¾„.xlsx]

    å¦‚æœä¸æä¾›å‚æ•°ï¼Œä¼šå¼¹å‡ºæ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†
"""

import sys
import os
import re
from pathlib import Path
from datetime import datetime
from tkinter import Tk, filedialog, messagebox
import pandas as pd

# Set paths
project_root = Path(__file__).resolve().parent.parent
os.chdir(project_root)
sys.path.insert(0, str(project_root))

from src.longitudinal_importer import LongitudinalDataImporter
from src.longitudinal_processor import LongitudinalEventProcessor
from src.logger import setup_logger


def extract_time_point_from_sheet_name(sheet_name: str) -> str:
    """
    ä»sheetåç§°ä¸­æå–æ—¶é—´ç‚¹ä¿¡æ¯

    ä¾‹å¦‚: 'ç¬¬ä¸‰ä¸ªæœˆéšè®¿_CAGSFB1_627CAGéšè®¿è¡¨1' -> '3ä¸ªæœˆ'
          'ç¬¬12ä¸ªæœˆéšè®¿_CAGSFB1_627CAGéšè®¿è¡¨1' -> '12ä¸ªæœˆ'
    """
    # ä¸­æ–‡æ•°å­—åˆ°é˜¿æ‹‰ä¼¯æ•°å­—çš„æ˜ å°„
    chinese_to_arabic = {
        "ä¸€": "1",
        "äºŒ": "2",
        "ä¸‰": "3",
        "å››": "4",
        "äº”": "5",
        "å…­": "6",
        "ä¸ƒ": "7",
        "å…«": "8",
        "ä¹": "9",
        "å": "10",
    }

    # å°è¯•åŒ¹é…"ç¬¬Xä¸ªæœˆ"æˆ–"ç¬¬Xæœˆ" (é˜¿æ‹‰ä¼¯æ•°å­—)
    match = re.search(r"ç¬¬(\d+)ä¸ª?æœˆ", sheet_name)
    if match:
        months = match.group(1)
        return f"{months}ä¸ªæœˆ"

    # å°è¯•åŒ¹é…ä¸­æ–‡æ•°å­— "ç¬¬Xä¸ªæœˆ" æˆ– "ç¬¬Xæœˆ"
    for chinese, arabic in chinese_to_arabic.items():
        match = re.search(rf"ç¬¬{chinese}ä¸ª?æœˆ", sheet_name)
        if match:
            return f"{arabic}ä¸ªæœˆ"

    # å¦‚æœæ˜¯personalæˆ–å…¶ä»–æ ¼å¼ï¼Œè¿”å›sheetåç§°
    return sheet_name


def extract_followup_sheets(input_file: Path, output_file: Path) -> None:
    """
    ä»åŸå§‹æ–‡ä»¶ä¸­æå–æ‰€æœ‰éšè®¿è¡¨1æ•°æ®å¹¶ä¿å­˜

    Args:
        input_file: åŸå§‹Excelæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
    """
    logger = setup_logger("extract_followup")

    logger.info(f"\næ­£åœ¨è¯»å–åŸå§‹æ–‡ä»¶: {input_file}")
    logger.info(f"æ–‡ä»¶å¤§å°: {input_file.stat().st_size / (1024*1024):.1f} MB")

    # è¯»å–Excelæ–‡ä»¶
    logger.info("\nåŠ è½½Excelæ–‡ä»¶ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    xls = pd.ExcelFile(input_file)

    logger.info(f"æ–‡ä»¶å…±æœ‰ {len(xls.sheet_names)} ä¸ªsheet")

    # æ‰¾åˆ°æ‰€æœ‰åŒ…å«"éšè®¿è¡¨1"çš„sheet
    followup_sheets = [name for name in xls.sheet_names if "éšè®¿è¡¨1" in name]
    logger.info(f"\næ‰¾åˆ° {len(followup_sheets)} ä¸ªéšè®¿è¡¨1 sheet:")
    for i, name in enumerate(followup_sheets, 1):
        time_point = extract_time_point_from_sheet_name(name)
        logger.info(f"  {i}. {name} -> {time_point}")

    # è¯»å–å¹¶é‡æ–°ç»„ç»‡æ•°æ®
    logger.info("\nå¼€å§‹æå–æ•°æ®...")
    with pd.ExcelWriter(output_file, engine="openpyxl") as writer:
        for sheet_name in followup_sheets:
            logger.info(f"  å¤„ç†: {sheet_name}")

            # è¯»å–æ•°æ®
            df = pd.read_excel(xls, sheet_name=sheet_name)

            # æå–æ—¶é—´ç‚¹ä½œä¸ºæ–°çš„sheetåç§°
            time_point = extract_time_point_from_sheet_name(sheet_name)

            # æ¸…ç†sheetåç§° (Excel sheetåç§°ä¸èƒ½è¶…è¿‡31å­—ç¬¦)
            if len(time_point) > 31:
                time_point = time_point[:31]

            # ä¿å­˜åˆ°æ–°æ–‡ä»¶
            df.to_excel(writer, sheet_name=time_point, index=False)
            logger.info(f"    -> å¯¼å‡ºä¸º: {time_point} ({len(df)} è¡Œ)")

    logger.info(f"\nâœ“ æå–å®Œæˆ!")
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    logger.info(f"è¾“å‡ºæ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024:.1f} KB")


def select_excel_file() -> str:
    """æ‰“å¼€æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†"""
    root = Tk()
    root.withdraw()
    root.attributes("-topmost", True)

    file_path = filedialog.askopenfilename(
        title="é€‰æ‹©åŸå§‹æ•°æ®æ–‡ä»¶ï¼ˆåŒ…å«å¤šä¸ªéšè®¿è¡¨Sheetï¼‰",
        initialdir=str(project_root / "data" / "raw"),
        filetypes=[("Excel files", "*.xlsx *.xls"), ("All files", "*.*")],
    )

    root.destroy()
    return file_path if file_path else None


def process_extracted_file(excel_file_path: str, patient_group: str = "CAG") -> bool:
    """
    å¤„ç†æå–åçš„æ–‡ä»¶

    Args:
        excel_file_path: æå–åçš„Excelæ–‡ä»¶è·¯å¾„
        patient_group: æ‚£è€…ç»„ç±»å‹ (CAG/PCI)

    Returns:
        bool: å¤„ç†æ˜¯å¦æˆåŠŸ
    """
    logger = setup_logger("process_followup")

    logger.info("=" * 60)
    logger.info("å¼€å§‹å¤„ç†çºµå‘éšè®¿æ•°æ®")
    logger.info(f"æ–‡ä»¶: {excel_file_path}")
    logger.info(f"æ‚£è€…ç»„: {patient_group}")
    logger.info("=" * 60)

    try:
        # 1. å¯¼å…¥æ•°æ®
        logger.info("\næ­¥éª¤ 1/3: å¯¼å…¥æ•°æ®")
        importer = LongitudinalDataImporter()
        if not importer.load_excel_file(excel_file_path):
            logger.error("âŒ åŠ è½½æ–‡ä»¶å¤±è´¥")
            return False
        logger.info(f"âœ… æˆåŠŸå¯¼å…¥ {len(importer.sheet_data)} ä¸ªæ—¶é—´ç‚¹çš„æ•°æ®")

        # 2. å¯¼å…¥çºµå‘æ•°æ®
        logger.info("\næ­¥éª¤ 2/3: å¯¼å…¥çºµå‘æ‚£è€…è®°å½•")
        longitudinal_records = importer.import_longitudinal_data()
        logger.info(f"âœ… æˆåŠŸå¯¼å…¥ {len(longitudinal_records)} æ¡æ‚£è€…è®°å½•")

        # 3. å¤„ç†äº‹ä»¶
        logger.info("\næ­¥éª¤ 3/3: å¤„ç†äº‹ä»¶æ•°æ®")
        processor = LongitudinalEventProcessor(endpoint="death")
        followup_records = processor.process_batch(longitudinal_records)
        logger.info(f"âœ… æˆåŠŸå¤„ç† {len(followup_records)} æ¡éšè®¿è®°å½•")

        # 4. å¯¼å‡ºç»“æœ
        logger.info("\næ­¥éª¤ 4/4: å¯¼å‡ºç»“æœ")
        output_data = [record.to_flattened_dict() for record in followup_records]
        df_output = pd.DataFrame(output_data)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = project_root / "output"
        output_dir.mkdir(exist_ok=True)

        # å¯¼å‡ºå®Œæ•´Excel
        output_filename = f"{patient_group}_followup_results_{timestamp}.xlsx"
        output_path = output_dir / output_filename
        df_output.to_excel(output_path, index=False, engine="openpyxl")
        logger.info(f"âœ… Excelå·²å¯¼å‡º: {output_filename}")

        # å¯¼å‡ºç”Ÿå­˜åˆ†æCSV
        survival_filename = f"survival_{patient_group}_{timestamp}.csv"
        try:
            survival_cols = [
                "patient_id",
                "patient_name",
                "birthday",
                "age",
                "gender",
                "group_name",
                "enrollment_date",
                "survival_time_days",
                "event_occurred",
                "endpoint_event",
            ]
            existing_cols = [c for c in survival_cols if c in df_output.columns]
            survival_df = df_output[existing_cols].copy()

            survival_path = output_dir / survival_filename
            survival_df.to_csv(survival_path, index=False)
            logger.info(f"âœ… ç”Ÿå­˜åˆ†æCSVå·²å¯¼å‡º: {survival_filename}")
        except Exception as e:
            logger.warning(f"âš ï¸ ç”Ÿå­˜åˆ†æCSVå¯¼å‡ºå¤±è´¥: {e}")

        logger.info("\n" + "=" * 60)
        logger.info("âœ… å¤„ç†å®Œæˆï¼")
        logger.info("=" * 60)
        logger.info(f"è¾“å‡ºæ–‡ä»¶:")
        logger.info(f"  - {output_filename}")
        logger.info(f"  - {survival_filename}")
        logger.info(f"æ‚£è€…æ•°é‡: {len(followup_records)}")

        # ç»Ÿè®¡ä¿¡æ¯
        has_event = sum(1 for r in followup_records if r.first_event_date is not None)
        logger.info(f"\nç»Ÿè®¡:")
        logger.info(f"  - æ€»æ‚£è€…æ•°: {len(followup_records)}")
        logger.info(
            f"  - å‘ç”Ÿäº‹ä»¶: {has_event} ({has_event/len(followup_records)*100:.1f}%)"
        )
        logger.info(f"  - æ— äº‹ä»¶: {len(followup_records) - has_event}")
        
        # è¯¦ç»†äº‹ä»¶åˆ†å¸ƒ
        logger.info(f"\nè¯¦ç»†äº‹ä»¶åˆ†å¸ƒ:")
        event_details = {
            "å¿ƒç»ç—›": df_output["first_angina_date"].notna().sum() if "first_angina_date" in df_output.columns else 0,
            "ä½é™¢": df_output["first_hospitalization_date"].notna().sum() if "first_hospitalization_date" in df_output.columns else 0,
            "å¿ƒè‚Œæ¢—æ­»": df_output["first_mi_date"].notna().sum() if "first_mi_date" in df_output.columns else 0,
            "å¿ƒè¡°": df_output["first_heart_failure_date"].notna().sum() if "first_heart_failure_date" in df_output.columns else 0,
            "è¡€è¿é‡å»º": df_output["first_revascularization_date"].notna().sum() if "first_revascularization_date" in df_output.columns else 0,
            "æ­»äº¡": df_output["first_death_date"].notna().sum() if "first_death_date" in df_output.columns else 0,
        }
        for event_name, count in event_details.items():
            if count > 0:
                logger.info(f"  - {event_name}: {count} ä¾‹")

        return True

    except Exception as e:
        logger.error(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    logger = setup_logger("extract_and_process")

    logger.info("\n" + "=" * 60)
    logger.info("éšè®¿è¡¨è‡ªåŠ¨æå–å’Œå¤„ç†å·¥å…·")
    logger.info("=" * 60)

    # è·å–æºæ–‡ä»¶è·¯å¾„
    if len(sys.argv) > 1:
        source_file = sys.argv[1]
    else:
        logger.info("\nè¯·é€‰æ‹©åŒ…å«éšè®¿è¡¨Sheetçš„åŸå§‹Excelæ–‡ä»¶...")
        source_file = select_excel_file()

    if not source_file:
        logger.warning("æœªé€‰æ‹©æ–‡ä»¶ï¼Œç¨‹åºé€€å‡º")
        return

    if not Path(source_file).exists():
        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {source_file}")
        return

    # æ£€æµ‹æ‚£è€…ç»„ç±»å‹
    patient_group = "CAG"  # é»˜è®¤
    filename = Path(source_file).name.upper()
    if "PCI" in filename:
        patient_group = "PCI"
    elif "CAG" in filename:
        patient_group = "CAG"
    else:
        # è¯¢é—®ç”¨æˆ·
        root = Tk()
        root.withdraw()
        response = messagebox.askquestion(
            "æ‚£è€…ç»„ç±»å‹",
            "è¿™æ˜¯ PCI ç»„æ‚£è€…å—ï¼Ÿ\n\næ˜¯ = PCIç»„\nå¦ = CAGç»„",
            icon="question",
        )
        patient_group = "PCI" if response == "yes" else "CAG"
        root.destroy()

    logger.info(f"\nè¯†åˆ«ä¸º: {patient_group} ç»„")

    # æ­¥éª¤1: æå–éšè®¿è¡¨Sheet
    logger.info("\n" + "=" * 60)
    logger.info("æ­¥éª¤ 1/2: ä»åŸå§‹æ–‡ä»¶æå–éšè®¿è¡¨1æ•°æ®")
    logger.info("=" * 60)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    source_path = Path(source_file)
    output_filename = f"extracted_{source_path.stem}_{timestamp}.xlsx"
    extracted_file = project_root / "data" / "raw" / output_filename

    try:
        extract_followup_sheets(Path(source_file), extracted_file)
    except Exception as e:
        logger.error(f"\næå–å¤±è´¥: {e}")
        input("\næŒ‰å›è½¦é”®é€€å‡º...")
        return

    # æ­¥éª¤2: å¤„ç†æå–åçš„æ–‡ä»¶
    logger.info("\n" + "=" * 60)
    logger.info("æ­¥éª¤ 2/2: å¤„ç†æ•°æ®å¹¶ç”Ÿæˆè¾“å‡º")
    logger.info("=" * 60)

    success = process_extracted_file(str(extracted_file), patient_group=patient_group)

    if success:
        logger.info("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")

        # è¯¢é—®æ˜¯å¦ä¿ç•™ä¸­é—´æ–‡ä»¶
        root = Tk()
        root.withdraw()
        keep_file = messagebox.askquestion(
            "ä¿ç•™ä¸­é—´æ–‡ä»¶ï¼Ÿ",
            f"æ˜¯å¦ä¿ç•™æå–çš„ä¸´æ—¶æ–‡ä»¶ï¼Ÿ\n\n{extracted_file}\n\n"
            f"ï¼ˆæ–‡ä»¶å·²ä¿å­˜åœ¨ data/raw/ ç›®å½•ï¼Œå¯ç”¨äºåç»­å¤„ç†ï¼‰",
            icon="question",
        )
        root.destroy()

        if keep_file == "no":
            try:
                extracted_file.unlink()
                logger.info(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {extracted_file}")
            except Exception as e:
                logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    else:
        logger.error("\nå¤„ç†å¤±è´¥")

    input("\næŒ‰å›è½¦é”®é€€å‡º...")


if __name__ == "__main__":
    main()
